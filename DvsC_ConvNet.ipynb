{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DvsC_ConvNet",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_VfUjArLfrsouQ9NEd5ItpbEABmO-K-5",
      "authorship_tag": "ABX9TyP2dUtq10hUgMuR91kBTsob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparro12/PyTorch/blob/main/DvsC_ConvNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63khI9jQlguS"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/gdrive\")\n",
        "\n",
        "# change to True if the data (i.e. npy file needs to be built)\n",
        "REBUILD_DATA = False\n",
        "MODEL_NAME = f\"model-{int(time.time())}\" # create model name based on current time\n",
        "\n",
        "class DogsvsCats():\n",
        "    img_size = 50\n",
        "    cats = \"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/PetImages/Cat\"\n",
        "    dogs = \"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/PetImages/Dog\"\n",
        "    testing = \"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/PetImages/Testing\"\n",
        "    labels = {cats: 0, dogs: 1}\n",
        "    training_data = []\n",
        "\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "\n",
        "    def make_training_data(self):\n",
        "        for label in self.labels:\n",
        "            for image in tqdm(os.listdir(label)):\n",
        "                if \"jpg\" in image:\n",
        "                    try:\n",
        "                        path = os.path.join(label, image)\n",
        "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                        img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "                        self.training_data.append([np.array(img), np.eye(2)[self.labels[label]]])\n",
        "\n",
        "                        if label == self.cats:\n",
        "                            self.catcount += 1\n",
        "                        elif label == self.dogs:\n",
        "                            self.dogcount += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        pass\n",
        "\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/training_data.npy\", self.training_data)\n",
        "        print(\"Cats:\", self.catcount)\n",
        "        print(\"Dogs:\", self.dogcount)\n",
        "\n",
        "# builds training data\n",
        "if REBUILD_DATA:\n",
        "    dogsvscats = DogsvsCats()\n",
        "    dogsvscats.make_training_data()\n",
        "\n",
        "training_data = np.load(\"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/training_data.npy\", allow_pickle=True)\n",
        "print(len(training_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bKgYaU1YovA"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # initializes parent class: nn.Module\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel/window\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, 64 output channels, 5x5 kernel/window\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        x = torch.randn(50,50).view(-1,1,50,50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "    def convs(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.view(-1, self._to_linear)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"# of GPUs: \" + str(torch.cuda.device_count()))\n",
        "  print(\"GPU name: \" + str(torch.cuda.get_device_name(0)))\n",
        "  print(\"Running on the GPU...\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Running on the CPU...\")\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct9jKnRyp6yP"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "loss_function = nn.MSELoss() # using MSELoss because output is a one hot vector (i.e. [0,1] or [1,0])\n",
        "\n",
        "# make pictures in training data 50x50 tensors\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50) # image\n",
        "X = X/255.0 # scale RGB values to avoid explosions\n",
        "Y = torch.Tensor([i[1] for i in training_data]) # one hot vector for type\n",
        "\n",
        "# percent of data reserved for testing\n",
        "VAL_PCT = 0.1\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "print(\"val_size =\", val_size)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_Y = Y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_Y = Y[-val_size:]\n",
        "\n",
        "print(\"train_X =\", len(train_X))\n",
        "print(\"test_X =\", len(test_X))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5DJSleQDgGu"
      },
      "source": [
        "def train(net, test_X, test_Y):\n",
        "  BATCH_SIZE = 100\n",
        "  EPOCHS = 30\n",
        "\n",
        "  with open(\"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/model.log\", \"a\") as f:\n",
        "    for epoch in range(EPOCHS):\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "            batch_Y = train_Y[i:i+BATCH_SIZE]\n",
        "\n",
        "            acc, loss = fwd_pass(batch_X, batch_Y, train=True)\n",
        "\n",
        "            # find in sample accuracy vs test accuracy and print it\n",
        "            val_acc, val_loss = test(size=100)\n",
        "            f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),2)},{round(float(loss), 4)},{round(float(val_acc),2)},{round(float(val_loss),4)},{epoch}\\n\")\n",
        "\n",
        "        print(\"\\nEpoch \"+str(epoch+1)+\": \"+str(loss))  \n",
        "\n",
        "def test(size=32):\n",
        "  X, Y = test_X[:size], test_Y[:size] # spliced array of size determined by size parameter\n",
        "  val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50), Y)\n",
        "  return val_acc, val_loss\n",
        "\n",
        "def fwd_pass(X, Y, train=False):\n",
        "  # put tensors on GPU\n",
        "  X, Y = X.to(device), Y.to(device)\n",
        "\n",
        "  if train:\n",
        "    net.zero_grad()\n",
        "  outputs = net(X)\n",
        "  matches = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, Y)] # find amount of correct prediction made by net\n",
        "  acc = matches.count(True)/len(matches)\n",
        "  loss = loss_function(outputs, Y)\n",
        "\n",
        "  if train:\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return acc, loss\n",
        "\n",
        "train(net, test_X, test_Y)\n",
        "test(size=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ineNlcAclkQa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "\n",
        "# graph the in sample accuracy/loss superimposed with test accuracy/loss over time \n",
        "def create_acc_loss_graph(model_name):\n",
        "    contents = open(\"/gdrive/MyDrive/Colab_Notebooks/CatsvsDogs/model.log\", \"r\").read().split(\"\\n\")\n",
        "\n",
        "    times = []\n",
        "    accuracies = []\n",
        "    losses = []\n",
        "\n",
        "    val_accs = []\n",
        "    val_losses = []\n",
        "    epochs = []\n",
        "\n",
        "    for c in contents:\n",
        "        if model_name in c:\n",
        "            name, timestamp, acc, loss, val_acc, val_loss, epoch = c.split(\",\")\n",
        "\n",
        "            times.append(float(timestamp))\n",
        "            accuracies.append(float(acc))\n",
        "            losses.append(float(loss))\n",
        "\n",
        "            val_accs.append(float(val_acc))\n",
        "            val_losses.append(float(val_loss))\n",
        "            epochs.append(float(epoch))\n",
        "\n",
        "\n",
        "    fig = plt.figure()\n",
        "\n",
        "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
        "    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n",
        "\n",
        "\n",
        "    ax1.plot(times, accuracies, label=\"in_sample_acc\")\n",
        "    ax1.plot(times, val_accs, label=\"test_acc\")\n",
        "    ax1.legend(loc=2)\n",
        "    ax2.plot(times,losses, label=\"in_sample_loss\")\n",
        "    ax2.plot(times,val_losses, label=\"test_loss\")\n",
        "    ax2.legend(loc=2)\n",
        "    plt.show()\n",
        "\n",
        "style.use(\"ggplot\")\n",
        "create_acc_loss_graph(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}